{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b538ce43",
   "metadata": {},
   "source": [
    "## 가위바위보 분류기를 만들자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6fdf20",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f99c39cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.22.2\n"
     ]
    }
   ],
   "source": [
    "#라이브러리 버전 확인 \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace4f19c",
   "metadata": {},
   "source": [
    "1. 데이터 만들기\n",
    "- 구글의 teachable machine 사용 \n",
    "- 가위,바위,보 각 100장의 (224, 224, 3)이미지를 만들기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494d053e",
   "metadata": {},
   "source": [
    "2. 데이터 불러오기 _Resize하기\n",
    "- 숫자 손글씨의 경우 이미지 크기가 28x28 이었기 때문에, 우리의 가위, 바위, 보 이미지도 28x28로 만듦\n",
    "-PIL 라이브러리 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89b6f688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90a17905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515  images to be resized.\n",
      "515  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")     \n",
    "\n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "#     # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# # 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfa0117a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515  images to be resized.\n",
      "515  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock/rock\"\n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2cfb8589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515  images to be resized.\n",
      "515  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper/paper\"\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47844b1c",
   "metadata": {},
   "source": [
    "3. load_data()함수 만들기\n",
    "- 입력으로 이미지가 있는 폴더 위치를 받음\n",
    "- 가위바위보의 경우 3개의 클래스 즉, 가위: 0, 바위: 1, 보: 2 로 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9bb4ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1545 입니다.\n",
      "x_train shape: (1545, 28, 28, 3)\n",
      "y_train shape: (1545,)\n"
     ]
    }
   ],
   "source": [
    "# 가위, 바위, 보 데이터를 읽을 수 있는 load_data() 함수\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=1545):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02212666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 abs불러오기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[11])\n",
    "print('라벨: ', y_train[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28189ad",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 설계하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9493fbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 97,475\n",
      "Trainable params: 97,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62daef9b",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 학습시키기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "98316fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/49 [==============================] - 3s 41ms/step - loss: 0.1715 - accuracy: 0.9430\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.0538 - accuracy: 0.9838\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.0274 - accuracy: 0.9968\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.0172 - accuracy: 0.9981\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.0319 - accuracy: 0.9935\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.0100 - accuracy: 0.9987\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 8.9303e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 8.4378e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 6.8490e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 6.6617e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 5.4059e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 5.9893e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 5.8914e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 4.2009e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb80a9e24c0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f0d7fc",
   "metadata": {},
   "source": [
    "### 얼마나 잘 만들었는지 확인하기(테스트)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70542d",
   "metadata": {},
   "source": [
    "1. 테스트데이터 x_test, y_test 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "017b6ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 0 입니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300, 28, 28, 3)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "\n",
    "test_image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "\n",
    "resize_images(test_image_dir_path + \"/scissor\")\n",
    "resize_images(test_image_dir_path + \"/rock\")\n",
    "resize_images(test_image_dir_path + \"/paper\")\n",
    "\n",
    "\n",
    "(x_test, y_test) = load_data(test_image_dir_path, number_of_data=300)\n",
    "x_test_norm = x_test.astype('float32') / 255.0\n",
    "x_test_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef6ac9",
   "metadata": {},
   "source": [
    "2. test_accuracy를 측정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8dbbd250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.1031 - accuracy: 0.0000e+00\n",
      "test_loss: 1.1030951738357544 \n",
      "test_accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b048e5",
   "metadata": {},
   "source": [
    "### 더 좋은 네트워크 만들어보기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7b157b",
   "metadata": {},
   "source": [
    "1. 학습데이터셋 추가\n",
    " 가위,바위,보 데이터넷 515개로 변경\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378cc94",
   "metadata": {},
   "source": [
    "2. 하이퍼파라미터 조정\n",
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "\n",
    "|n_channel_1|n_channel_2|n_dense|n_train_epoch|accuracy|\n",
    "|---|---|---|---|---|\n",
    "|32|32|32|10|0.4099999964237213|\n",
    "|16|32|32|10|0.3566666543483734|\n",
    "|64|32|32|10|0.3499999940395355|\n",
    "|32|64|32|10|0.3100000023841858|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c5eeb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 3, 3, 128)         36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 51,363\n",
      "Trainable params: 51,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=20\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3e6d893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 38ms/step - loss: 7.1921 - accuracy: 0.4200\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 1.0816 - accuracy: 0.5367\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.9981 - accuracy: 0.5500\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.5551 - accuracy: 0.7700\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.3905 - accuracy: 0.8633\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.2508 - accuracy: 0.9633\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.1755 - accuracy: 0.9733\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.1248 - accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.0800 - accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.0646 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb812fb9d30>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c84e308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.7889 - accuracy: 0.3100\n",
      "test_loss: 1.7888669967651367 \n",
      "test_accuracy: 0.3100000023841858\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2d157",
   "metadata": {},
   "source": [
    "내 데이터만 가지고 학습을 시켰을때는 accuracy 측정이 되었는데 개선을 위해 데이터를 추가한 이후 accuracy 측정이 안되었다. \n",
    "테스트 이후에 코드에 대해서 재학습이 필요하다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
